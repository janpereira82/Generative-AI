# Agente Pesquisador Web
Um sistema avan√ßado de pesquisa web automatizada constru√≠do com crewAI, que utiliza m√∫ltiplos agentes especializados para realizar pesquisas abrangentes, extrair conte√∫do relevante e sintetizar informa√ß√µes em relat√≥rios detalhados.

## Vis√£o Geral
O Agente Pesquisador Web √© uma aplica√ß√£o que automatiza o processo de pesquisa na internet, utilizando intelig√™ncia artificial para descobrir, extrair e sintetizar informa√ß√µes sobre qualquer t√≥pico. O sistema emprega uma arquitetura de m√∫ltiplos agentes especializados, cada um respons√°vel por uma etapa espec√≠fica do processo de pesquisa.

## Funcionalidades
- **Busca Web Automatizada**: Utiliza a API SerperDev para encontrar fontes relevantes e diversificadas
- **Extra√ß√£o Inteligente de Conte√∫do**: Processa p√°ginas web para extrair informa√ß√µes significativas
- **S√≠ntese de Informa√ß√µes**: Cria relat√≥rios detalhados baseados exclusivamente no conte√∫do extra√≠do
- **Rastreamento de Refer√™ncias**: Mant√©m registro de todas as fontes consultadas
- **Armazenamento de Resultados**: Salva automaticamente os relat√≥rios em arquivos de texto
- **Interface em Linha de Comando**: F√°cil de usar, com instru√ß√µes em portugu√™s

## Requisitos
- Python 3.8 ou superior
- Chaves de API:
  - OpenAI API Key
  - SerperDev API Key

## Instala√ß√£o
1. Clone o reposit√≥rio
2. Instale as depend√™ncias:
```bash
pip install -r requirements.txt
```
3. Configure as vari√°veis de ambiente no arquivo `.env`:
```env
OPENAI_API_KEY=sua_chave_openai
SERPER_API_KEY=sua_chave_serperdev
```

## Bibliotecas Utilizadas
- **crewAI**: Framework para cria√ß√£o e orquestra√ß√£o de agentes aut√¥nomos
- **langchain_openai**: Integra√ß√£o com modelos de linguagem da OpenAI
- **crewai_tools**: Ferramentas espec√≠ficas para o crewAI, incluindo SerperDevTool
- **BeautifulSoup4**: Biblioteca para an√°lise e extra√ß√£o de conte√∫do HTML
- **requests**: Biblioteca para realizar requisi√ß√µes HTTP
- **python-dotenv**: Gerenciamento de vari√°veis de ambiente
- **datetime**: Manipula√ß√£o de datas e horas
- **re**: Processamento de express√µes regulares

## Como Funciona

O script `main.py` implementa uma arquitetura de tr√™s agentes especializados que trabalham em sequ√™ncia:

### 1. Agente Explorador

- **Fun√ß√£o**: Especialista em busca web
- **Objetivo**: Encontrar e coletar URLs relevantes para o t√≥pico de pesquisa
- **Ferramentas**: SerperDevTool para busca web
- **Modelo**: GPT-4o-mini

### 2. Agente Pesquisador

- **Fun√ß√£o**: Especialista em extra√ß√£o de conte√∫do
- **Objetivo**: Extrair conte√∫do web dos URLs fornecidos e armazen√°-lo para an√°lise
- **Ferramentas**: Ferramenta personalizada de extra√ß√£o de conte√∫do
- **Modelo**: GPT-4-turbo-preview

### 3. Agente Sintetizador

- **Fun√ß√£o**: Sintetizador de pesquisa
- **Objetivo**: Criar um relat√≥rio abrangente baseado no conte√∫do web extra√≠do
- **Ferramentas**: Ferramenta de acesso ao conte√∫do extra√≠do
- **Modelo**: GPT-4-turbo-preview

### Fluxo de Trabalho
1. O usu√°rio fornece um t√≥pico de pesquisa
2. O Agente Explorador busca e identifica pelo menos 15 URLs relevantes
3. O Agente Pesquisador extrai o conte√∫do de cada URL, removendo elementos irrelevantes
4. O Agente Sintetizador analisa todo o conte√∫do extra√≠do e cria um relat√≥rio detalhado
5. O sistema adiciona uma se√ß√£o de refer√™ncias ao relat√≥rio
6. O relat√≥rio final √© salvo em um arquivo de texto na pasta "resultados"

## Uso
Execute o script principal:
```bash
python main.py
```

Siga as instru√ß√µes na interface de linha de comando:
1. Digite o t√≥pico que deseja pesquisar
2. Aguarde enquanto os agentes realizam a pesquisa (pode levar alguns minutos)
3. O resultado ser√° exibido no terminal e salvo automaticamente na pasta "resultados"

## Estrutura do Projeto
- `main.py`: Script principal contendo a implementa√ß√£o dos agentes e do fluxo de trabalho
- `requirements.txt`: Lista de depend√™ncias do projeto
- `.env`: Arquivo de configura√ß√£o para chaves de API
- `resultados/`: Diret√≥rio onde os relat√≥rios de pesquisa s√£o salvos

## Resultados
O sistema gera relat√≥rios detalhados que incluem:

- Informa√ß√µes abrangentes sobre o t√≥pico pesquisado
- An√°lise baseada exclusivamente no conte√∫do extra√≠do das fontes web
- Cita√ß√µes adequadas para todas as informa√ß√µes apresentadas
- Lista completa de refer√™ncias (URLs) consultadas durante a pesquisa

Os relat√≥rios s√£o salvos como arquivos de texto na pasta "resultados" com nomes que incluem o t√≥pico pesquisado e um timestamp, por exemplo: `inteligencia_artificial_20230615_143022.txt`.

## Tratamento de Erros
O sistema inclui tratamento robusto de erros para lidar com:

- Problemas de conex√£o com a internet
- URLs inv√°lidos ou inacess√≠veis
- P√°ginas web com conte√∫do insuficiente
- Falhas nas APIs externas

## Limita√ß√µes
- Requer chaves de API v√°lidas para OpenAI e SerperDev
- O tempo de processamento pode variar dependendo da complexidade do t√≥pico
- A qualidade dos resultados depende da disponibilidade de informa√ß√µes online sobre o t√≥pico

## üë®‚Äçüíª Autor
[Jan Pereira](https://github.com/janpereira82)